{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "ERROR 1: PROJ: proj_create_from_database: Open of /ccsopen/home/braut/analysis-env2/share/proj failed\n",
      "/ccsopen/home/braut/analysis-env2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220818.073342.nc\n",
      "csv created\n",
      "Processing file 1/7408: /gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220801.001324.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ccsopen/home/braut/analysis-env2/lib/python3.10/site-packages/pyart/io/cfradial.py:376: UserWarning: WARNING: valid_min not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  data = self.ncvar[:]\n",
      "/ccsopen/home/braut/analysis-env2/lib/python3.10/site-packages/pyart/io/cfradial.py:376: UserWarning: WARNING: valid_max not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  data = self.ncvar[:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 2/7408: /gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220801.003123.nc\n",
      "Processing file 3/7408: /gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220801.003723.nc\n",
      "Processing file 4/7408: /gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220801.004323.nc\n",
      "Processing file 5/7408: /gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220801.004923.nc\n",
      "Processing file 6/7408: /gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi/202208/gucxprecipradarcmacS2.c1.20220801.005523.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import xradar as xd\n",
    "import glob\n",
    "import pyart\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import gc\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Parameters\n",
    "lat = 38.956158 \n",
    "lon = -106.987854\n",
    "level = 1\n",
    "data_dir = '/gpfs/wolf2/arm/atm124/world-shared/gucxprecipradarcmacS2.c1/ppi'\n",
    "output_csv = f'radar_data_lev{level}.csv'\n",
    "\n",
    "def open_csv(output_csv, keys_to_extract):\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['time'] + keys_to_extract)\n",
    "        writer.writeheader()\n",
    "\n",
    "def process_single_file(file, loc, keys_to_extract):\n",
    "    radar = pyart.io.read_cfradial(file)\n",
    "    radar.time['units'] = 'seconds since 1970-01-01'\n",
    "    radar.time['data'] = radar.time['data'] / 1000\n",
    "\n",
    "    guc_df = pyart.util.columnsect.get_field_location(radar, loc[0], loc[1])\n",
    "\n",
    "    radar_time = int(radar.time['data'][0])\n",
    "    radar_time_str = datetime.utcfromtimestamp(radar_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    row_data = {'time': radar_time_str}\n",
    "    for key in keys_to_extract:\n",
    "        row_data[key] = guc_df[key].values[level] if key in guc_df else None\n",
    "    \n",
    "    del radar\n",
    "    del guc_df\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return row_data\n",
    "\n",
    "def append_to_csv(output_csv, row_data):\n",
    "    with open(output_csv, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=row_data.keys())\n",
    "        writer.writerow(row_data)\n",
    "\n",
    "def get_last_timestamp(output_csv):\n",
    "    try:\n",
    "        df = pd.read_csv(output_csv)\n",
    "        if not df.empty:\n",
    "            last_timestamp = df['time'].max()\n",
    "            return datetime.strptime(last_timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def filter_files_by_timestamp(files, last_timestamp):\n",
    "    filtered_files = []\n",
    "    for file in files:\n",
    "        match = re.search(r\"(\\d{8}\\.\\d{6})\", file)\n",
    "        if match:\n",
    "            file_time_str = match.group(1).replace('.', '')\n",
    "            file_time = datetime.strptime(file_time_str, '%Y%m%d%H%M%S')\n",
    "            if last_timestamp is None or file_time > last_timestamp:\n",
    "                filtered_files.append(file)\n",
    "    return filtered_files\n",
    "\n",
    "def process_radar_files(files, loc, output_csv):\n",
    "    keys_to_extract = ['DBZ', 'VEL', 'WIDTH', 'ZDR', 'PHIDP', 'RHOHV', 'NCP', 'DBZhv', \n",
    "                       'cbb_flag', 'sounding_temperature', 'height', 'signal_to_noise_ratio', \n",
    "                       'velocity_texture', 'gate_id', 'simulated_velocity', 'corrected_velocity', \n",
    "                       'unfolded_differential_phase', 'corrected_differential_phase', \n",
    "                       'filtered_corrected_differential_phase', 'corrected_specific_diff_phase', \n",
    "                       'filtered_corrected_specific_diff_phase', 'corrected_differential_reflectivity', \n",
    "                       'corrected_reflectivity', 'height_over_iso0', 'specific_attenuation', \n",
    "                       'path_integrated_attenuation', 'specific_differential_attenuation', \n",
    "                       'path_integrated_differential_attenuation', 'rain_rate_A', 'snow_rate_ws2012', \n",
    "                       'snow_rate_ws88diw', 'snow_rate_m2009_1', 'snow_rate_m2009_2']\n",
    "    \n",
    "    if not os.path.exists(output_csv):\n",
    "        open_csv(output_csv, keys_to_extract)\n",
    "        print(\"csv created\")\n",
    "\n",
    "    last_timestamp = get_last_timestamp(output_csv)\n",
    "    files = filter_files_by_timestamp(files, last_timestamp)\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        try:\n",
    "            print(f\"Processing file {i + 1}/{len(files)}: {file}\")\n",
    "            row_data = process_single_file(file, loc, keys_to_extract)\n",
    "            append_to_csv(output_csv, row_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    year = '2022'\n",
    "    month = '08'\n",
    "    files = glob.glob(f'{data_dir}/{year}{month}/gucxprecipradarcmacS2.c1.{year}{month}*')\n",
    "    print(files[0])\n",
    "    files.sort()\n",
    "    process_radar_files(files, (lat, lon), output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7408"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-env2",
   "language": "python",
   "name": "analysis-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
